{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "technocolabs prob 2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1O2hVtneOHhgK9sSUzWcid6SX5LvH1rYz",
      "authorship_tag": "ABX9TyO8FdKS5ZYzC7uZzcoJFjfd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/maheshkajjari/Technocolabs/blob/main/technocolabs_prob_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fw073CcJv1c_"
      },
      "source": [
        "import tqdm\n",
        "import os\n",
        "import tensorflow as tf\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
        "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vodVNTYvwGoW",
        "outputId": "d42440d2-524a-4366-9028-8c563e9ec026",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#\n",
        "#  Script variables. Change these and observe\n",
        "#  how results change.\n",
        "#\n",
        "LEARNING_RATE =  0.1\n",
        "EPOCHS = 100\n",
        "\n",
        "#\n",
        "#  Script constants. Here we pull data available\n",
        "#  locally. The data contains both the sprites\n",
        "#  and the labels from the original MNIST dataset.\n",
        "#\n",
        "LOGDIR = \"mnist_example/\"\n",
        "LABELS = os.path.join(os.getcwd(), \"/content/drive/My Drive/technocolabs/labels_1024.tsv\")\n",
        "SPRITES = os.path.join(os.getcwd(), \"/content/drive/My Drive/technocolabs/sprite_1024.png\")\n",
        "\n",
        "\n",
        "def load_data():\n",
        "    \"\"\"Load data form the MNIST dataset into memory.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    TensorFlow object with dataset.\n",
        "    \"\"\"\n",
        "    if not (os.path.isfile(LABELS) and os.path.isfile(SPRITES)):\n",
        "        raise ValueError(\"\"\"\n",
        "            Necessary data files were not found. Make sure the files\n",
        "\n",
        "                * labels_1024.tsv\n",
        "                * sprite_1024.png\n",
        "\n",
        "            are available in the same location where you run this script.\n",
        "            \"\"\")\n",
        "\n",
        "    return tf.contrib.learn.datasets.mnist.read_data_sets(\n",
        "        train_dir=LOGDIR + \"data\", one_hot=True)\n",
        "\n",
        "\n",
        "def convolutional_layer(input, size_in, size_out, name=\"convolutional\"):\n",
        "    \"\"\"Convoluted layer.\n",
        "\n",
        "    Create the weights and biases distributions.\n",
        "    Also define the convolution and the activation function (ReLU).\n",
        "    Finally, we create some histogram summaries useful for TensorBoard.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    size_in, size_out: int or float\n",
        "        Where to truncate the normal distribution.\n",
        "\n",
        "    name: str\n",
        "        Name to give the TensorFlow scope.\n",
        "    \"\"\"\n",
        "    with tf.name_scope(name):\n",
        "\n",
        "        W = tf.Variable(tf.truncated_normal([5, 5, size_in, size_out], stddev=0.1), name=\"Weights\")\n",
        "        B = tf.Variable(tf.constant(0.1, shape=[size_out]), name=\"Biases\")\n",
        "\n",
        "        convolution = tf.nn.conv2d(input, W, strides=[1, 1, 1, 1], padding=\"SAME\")\n",
        "        activation = tf.nn.relu(convolution + B)\n",
        "\n",
        "        tf.summary.histogram(\"weights\", W)\n",
        "        tf.summary.histogram(\"biases\", B)\n",
        "        tf.summary.histogram(\"activations\", activation)\n",
        "\n",
        "        return tf.nn.max_pool(activation, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\"SAME\")\n",
        "\n",
        "\n",
        "def fully_connected_layer(input, size_in, size_out, name=\"fully_connected\"):\n",
        "    \"\"\"Fully connected layer.\n",
        "\n",
        "    This defines the fully connected layer.\n",
        "    Different from the convolution layer, this layer does not\n",
        "    perform a convolution but only defines an activation function.\n",
        "    That function is also different from the convolution layer\n",
        "    by multipliying the input data with its weights plus the biases,\n",
        "    which is a much simpler activation function than ReLU.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    size_in, size_out: int or float\n",
        "        Where to truncate the normal distribution.\n",
        "\n",
        "    name: str\n",
        "        Name to give the TensorFlow scope.\n",
        "    \"\"\"\n",
        "    with tf.name_scope(name):\n",
        "        W = tf.Variable(tf.truncated_normal([size_in, size_out], stddev=0.1), name=\"Weights\")\n",
        "        B = tf.Variable(tf.constant(0.1, shape=[size_out]), name=\"Biases\")\n",
        "\n",
        "        activation = tf.matmul(input, W) + B\n",
        "\n",
        "        tf.summary.histogram(\"weights\", W)\n",
        "        tf.summary.histogram(\"biases\", B)\n",
        "        tf.summary.histogram(\"activations\", activation)\n",
        "\n",
        "        return activation\n",
        "\n",
        "\n",
        "def model(mnist, learning_rate, epochs=2000):\n",
        "    \"\"\"Neural network model used in the MNIST dataset.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    mnist: TensorFlow dataset object\n",
        "        MNIST dataset loaded using TensorFlow.\n",
        "\n",
        "    learning_rate: float\n",
        "        Learning rate at which the network should\n",
        "        create momentum.\n",
        "\n",
        "    epochs: int, default 2000\n",
        "        Number of epochs to train the model with.\n",
        "    \"\"\"\n",
        "    name = \"MNIST-model/lr={}-epochs={}\".format(learning_rate, epochs)\n",
        "\n",
        "    tf.reset_default_graph()\n",
        "    sess = tf.Session()\n",
        "\n",
        "    X = tf.placeholder(tf.float32, shape=[None, 784], name=\"X\")\n",
        "    X_image = tf.reshape(X, [-1, 28, 28, 1])\n",
        "    tf.summary.image('input', X_image, 3)\n",
        "\n",
        "    Y = tf.placeholder(tf.float32, shape=[None, 10], name=\"Labels\")\n",
        "\n",
        "    #\n",
        "    #  Convolutional layer treatment. We use a single convolutional layer.\n",
        "    #\n",
        "    convolution = convolutional_layer(X_image, 1, 64, \"Convolution_Layer\")\n",
        "    convolution_output = tf.nn.max_pool(convolution, ksize=[1, 2, 2, 1],\n",
        "                                        strides=[1, 2, 2, 1], padding=\"SAME\")\n",
        "\n",
        "    flattened = tf.reshape(convolution_output, [-1, 7 * 7 * 64])\n",
        "\n",
        "    #\n",
        "    #  Fully-connected layer treatment.\n",
        "    #  We will use two fully connected layers\n",
        "    #  that connect to each other. We can\n",
        "    #  try more or less to see the impact\n",
        "    #  on our model.\n",
        "    #\n",
        "    fully_connected_1 = fully_connected_layer(flattened, 7 * 7 * 64, 1024,\n",
        "                                              \"Fully-connected_Layer_1\")\n",
        "    relu = tf.nn.relu(fully_connected_1)\n",
        "    embedding_input = relu\n",
        "    tf.summary.histogram(\"Fully-connected_Layer-1/relu\", relu)\n",
        "\n",
        "    embedding_size = 1024\n",
        "    logits = fully_connected_layer(fully_connected_1, 1024, 10,\n",
        "                                   \"Fully-connected_Layer_2\")\n",
        "\n",
        "    with tf.name_scope(\"Cross_Entropy\"):\n",
        "        cross_entropy = tf.reduce_mean(\n",
        "            tf.nn.softmax_cross_entropy_with_logits(\n",
        "                logits=logits, labels=Y), name=\"cross_entropy\")\n",
        "\n",
        "        tf.summary.scalar(\"cross_entropy\", cross_entropy)\n",
        "\n",
        "    with tf.name_scope(\"Train\"):\n",
        "        train_step = tf.train.AdamOptimizer(learning_rate).minimize(cross_entropy)\n",
        "\n",
        "    with tf.name_scope(\"Accuracy\"):\n",
        "        correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(Y, 1))\n",
        "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "\n",
        "        tf.summary.scalar(\"Accuracy\", accuracy)\n",
        "\n",
        "    summ = tf.summary.merge_all()\n",
        "\n",
        "    #\n",
        "    #  Let's save embeddings so that they\n",
        "    #  are available in TensorBoard.\n",
        "    #\n",
        "    embedding = tf.Variable(tf.zeros([1024, embedding_size]), name=\"Test_Embedding\")\n",
        "    assignment = embedding.assign(embedding_input)\n",
        "    saver = tf.train.Saver()\n",
        "\n",
        "    #\n",
        "    #  We can now run our TensorFlow session.\n",
        "    #\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    writer = tf.summary.FileWriter(LOGDIR + name)\n",
        "    writer.add_graph(sess.graph)\n",
        "\n",
        "    config = tf.contrib.tensorboard.plugins.projector.ProjectorConfig()\n",
        "    embedding_config = config.embeddings.add()\n",
        "    embedding_config.tensor_name = embedding.name\n",
        "    embedding_config.sprite.image_path = SPRITES\n",
        "    embedding_config.metadata_path = LABELS\n",
        "\n",
        "    #\n",
        "    #  Create each thumbnail.\n",
        "    #\n",
        "    embedding_config.sprite.single_image_dim.extend([28, 28])\n",
        "    tf.contrib.tensorboard.plugins.projector.visualize_embeddings(writer, config)\n",
        "\n",
        "    for i in tqdm.tqdm(range(epochs + 1), 'Epochs'):\n",
        "        batch = mnist.train.next_batch(100)\n",
        "\n",
        "        if i % 5 == 0:\n",
        "            [train_accuracy, s] = sess.run([accuracy, summ], feed_dict={X: batch[0], Y: batch[1]})\n",
        "            writer.add_summary(s, i)\n",
        "        if i % 500 == 0:\n",
        "            sess.run(assignment, feed_dict={\n",
        "                X: mnist.test.images[:1024],\n",
        "                Y: mnist.test.labels[:1024]\n",
        "            })\n",
        "            saver.save(sess, os.path.join(LOGDIR, \"model.ckpt\"), i)\n",
        "\n",
        "        sess.run(train_step, feed_dict={X: batch[0], Y: batch[1]})\n",
        "\n",
        "    print('Done training!')\n",
        "    print('Run `tensorboard --logdir=%s` to see the results.' % LOGDIR)\n",
        "\n",
        "\n",
        "def main():\n",
        "    \"\"\"Main runner function.\n",
        "\n",
        "    This calls the model function.\n",
        "    \"\"\"\n",
        "    print(\"\"\"\n",
        "    Running MNIST model with:\n",
        "\n",
        "        * Learning rate: {}\n",
        "        * Epochs: {}\n",
        "\n",
        "    \"\"\".format(LEARNING_RATE, EPOCHS))\n",
        "\n",
        "    mnist = load_data()\n",
        "    model(mnist=mnist, learning_rate=LEARNING_RATE, epochs=EPOCHS)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "    Running MNIST model with:\n",
            "\n",
            "        * Learning rate: 0.1\n",
            "        * Epochs: 100\n",
            "\n",
            "    \n",
            "Extracting mnist_example/data/train-images-idx3-ubyte.gz\n",
            "Extracting mnist_example/data/train-labels-idx1-ubyte.gz\n",
            "Extracting mnist_example/data/t10k-images-idx3-ubyte.gz\n",
            "Extracting mnist_example/data/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epochs: 100%|██████████| 101/101 [00:20<00:00,  4.83it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Done training!\n",
            "Run `tensorboard --logdir=mnist_example/` to see the results.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}